{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8qyVJ4vRNh6"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleanup previous dataset directories if they exist\n",
        "!rm -rf Scratched_Cars/\n",
        "!rm -rf Undamaged_Cars/\n",
        "!rm -rf best_checkpoint/\n",
        "!rm -rf data1a/\n",
        "!rm -rf dataset/\n",
        "!rm best_checkpoint.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unhb3BiLShwR",
        "outputId": "eba6f9b2-6812-495c-e295-72c010309ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'best_checkpoint.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for dataset zips and copy datasets from Drive\n",
        "!mkdir dataset_zip\n",
        "!cp -r datensatz2/* dataset_zip\n",
        "\n",
        "# Unzip datasets and organize them into respective folders\n",
        "!unzip -qo dataset_zip/Scratched_Cars/Scratched_Cars.zip\n",
        "!cp -r dataset_zip/Undamaged_Cars/Undamaged_Cars Undamaged_Cars\n",
        "!rm -rf dataset_zip  # Clean up the zip directory after extraction"
      ],
      "metadata": {
        "id": "OdiIVb9tSkgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check and remove any invalid image files in a folder\n",
        "def check_images_in_folder(folder_path):\n",
        "    valid_images = []\n",
        "    invalid_images = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            with Image.open(file_path) as img:\n",
        "                img.verify()  # Verify if it's an image. This is important as some are corrupted\n",
        "            valid_images.append(filename)\n",
        "        except (IOError, SyntaxError) as e:\n",
        "            invalid_images.append(filename)\n",
        "    return invalid_images\n",
        "\n",
        "# Function to get all valid image paths from a directory\n",
        "def get_image_paths(directory):\n",
        "    \"\"\"Get all image paths in a given directory.\"\"\"\n",
        "    return [os.path.join(directory, file) for file in os.listdir(directory) if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Function to undersample image paths from two directories for balanced classes\n",
        "def undersample_paths(dir1, dir2):\n",
        "    \"\"\"Undersample image paths from two directories to create balanced classes.\"\"\"\n",
        "    paths1 = get_image_paths(dir1)\n",
        "    paths2 = get_image_paths(dir2)\n",
        "    min_count = min(len(paths1), len(paths2))\n",
        "    paths1 = random.sample(paths1, min_count) if len(paths1) > min_count else paths1\n",
        "    paths2 = random.sample(paths2, min_count) if len(paths2) > min_count else paths2\n",
        "    return paths1, paths2\n",
        "\n",
        "# Function to split dataset paths into train, test, and validation sets\n",
        "def split_data(paths, train_ratio, test_ratio):\n",
        "    \"\"\"Split data into train, test, and validation sets.\"\"\"\n",
        "    random.shuffle(paths)\n",
        "    train_size = int(len(paths) * train_ratio)\n",
        "    test_size = int(len(paths) * test_ratio)\n",
        "    train_paths = paths[:train_size]\n",
        "    test_paths = paths[train_size:train_size + test_size]\n",
        "    val_paths = paths[train_size + test_size:]\n",
        "    return train_paths, test_paths, val_paths\n",
        "\n",
        "# Function to copy files to a specified destination\n",
        "def copy_files(file_paths, destination):\n",
        "    \"\"\"Copy files to a specified destination.\"\"\"\n",
        "    for path in file_paths:\n",
        "        shutil.copy(path, destination)\n",
        "\n",
        "# Define the class names and dataset directory structure\n",
        "class_names = ['Scratched_Cars', 'Undamaged_Cars']\n",
        "dataset_base = 'dataset'\n",
        "subfolders = ['train', 'test', 'validation']\n",
        "\n",
        "# Remove invalid images from each class directory\n",
        "for folder in class_names:\n",
        "  invalid_images = check_images_in_folder(folder)\n",
        "  for invalid_image in invalid_images:\n",
        "    os.remove(os.path.join(folder, invalid_image))\n",
        "    print(\"Removed invalid image:\", os.path.join(folder, invalid_image))\n",
        "\n",
        "# Get balanced paths for each class and prepare the dataset directory structure\n",
        "balanced_paths1, balanced_paths2 = undersample_paths(class_names[0], class_names[1])\n",
        "for subfolder in subfolders:\n",
        "    os.makedirs(os.path.join(dataset_base, subfolder), exist_ok=True)\n",
        "    for class_name in class_names:\n",
        "        os.makedirs(os.path.join(dataset_base, subfolder, class_name), exist_ok=True)\n",
        "\n",
        "# Split and copy the data for each class into the dataset structure\n",
        "for idx, paths in enumerate([balanced_paths1, balanced_paths2]):\n",
        "    train, test, val = split_data(paths, train_ratio=0.7, test_ratio=0.1)\n",
        "    copy_files(train, os.path.join(dataset_base, 'train', class_names[idx]))\n",
        "    copy_files(test, os.path.join(dataset_base, 'test', class_names[idx]))\n",
        "    copy_files(val, os.path.join(dataset_base, 'validation', class_names[idx]))\n",
        "\n",
        "print(\"Data successfully split and copied into the dataset folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS4wcM6CSyZM",
        "outputId": "33b2fb54-e04c-4034-a5d5-2bab128cc456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed invalid image: Undamaged_Cars/DPt8y4MuGLLqrM.jpg\n",
            "Removed invalid image: Undamaged_Cars/nPI1plBku-ZD1M.jpg\n",
            "Removed invalid image: Undamaged_Cars/tMz-ivnVKZubCM.jpg\n",
            "Removed invalid image: Undamaged_Cars/njbaSQCRRyICzM.jpg\n",
            "Removed invalid image: Undamaged_Cars/Zp5HSkz4B2prRM.jpg\n",
            "Removed invalid image: Undamaged_Cars/50PYbIvq7UBYhM.jpg\n",
            "Data successfully split and copied into the dataset folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a dataset from a directory\n",
        "def create_dataset_from_dir(dir):\n",
        "    \"\"\"Create a dataset from the given directory with specified parameters.\"\"\"\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        dir,\n",
        "        labels=\"inferred\",  # Automatically infer labels from directory structure\n",
        "        label_mode=\"categorical\",  # For multi-class classification\n",
        "        color_mode=\"rgb\",  # Use RGB images\n",
        "        batch_size=16,  # Number of samples per batch\n",
        "        image_size=(224, 224),  # Resize images to 224x224\n",
        "        shuffle=True,  # Shuffle the data\n",
        "        seed=42,  # Seed for shuffling and transformations\n",
        "        interpolation=\"bilinear\"  # Interpolation method for resizing\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "# Load the datasets\n",
        "print(\"Training:\")\n",
        "training_set = create_dataset_from_dir('dataset/train');\n",
        "print(\"\\nValidation:\")\n",
        "validation_set = create_dataset_from_dir('dataset/validation');\n",
        "print(\"\\nTesting:\")\n",
        "testing_set = create_dataset_from_dir('dataset/test');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOYuwhHjVrDH",
        "outputId": "16c3e384-6863-4222-8057-1f1c2b32d0a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:\n",
            "Found 444 files belonging to 2 classes.\n",
            "\n",
            "Validation:\n",
            "Found 130 files belonging to 2 classes.\n",
            "\n",
            "Testing:\n",
            "Found 62 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some metadata about the datasets\n",
        "print(\"Classes:\", training_set.class_names)  # Print class names\n",
        "print(\"Number of batches:\", len(training_set))  # Print the number of batches in the training set\n",
        "\n",
        "# Example of accessing and printing metadata for a single batch\n",
        "for images, labels in training_set.take(1):  # Access a single batch\n",
        "    print(\"Batch shape:\", images.shape)  # Print shape of the batch (images)\n",
        "    print(\"Label shape:\", labels.shape)  # Print shape of the labels\n",
        "    print(\"First 10 labels in the first batch:\", labels[:10])  # Print first 10 labels of the batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XRYvpTaV9Ko",
        "outputId": "377ca9b4-ec8b-48fc-ed5f-c1401610ef48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Scratched_Cars', 'Undamaged_Cars']\n",
            "Number of batches: 28\n",
            "Batch shape: (16, 224, 224, 3)\n",
            "Label shape: (16, 2)\n",
            "First 10 labels in the first batch: tf.Tensor(\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]], shape=(10, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the model checkpoint callback\n",
        "checkpoint = ModelCheckpoint(\n",
        "    './best_checkpoint',  # Path where to save the model\n",
        "    monitor='val_accuracy',  # Monitor validation accuracy for improvement\n",
        "    verbose=1,  # Verbosity mode\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode='max',  # Maximize the monitored metric (val_accuracy)\n",
        "    save_weights_only=False,  # Save the entire model, not just weights\n",
        "    save_frequency=1  # Checkpoint saving frequency\n",
        ")"
      ],
      "metadata": {
        "id": "e3nhUNUlWNI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the early stopping callback\n",
        "earlystop = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss for stopping\n",
        "    min_delta=0.001,  # Minimum change to qualify as an improvement\n",
        "    patience=50,  # How many epochs to wait after last time val_loss improved\n",
        "    verbose=1,  # Verbosity mode\n",
        "    mode='auto'  # The direction of monitoring (auto detects automatically)\n",
        ")"
      ],
      "metadata": {
        "id": "RTRyf4dtWPCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_misclassified_images(testing_set, model):\n",
        "    \"\"\"\n",
        "    Save images that were misclassified by the model during testing.\n",
        "\n",
        "    Args:\n",
        "        testing_set: The dataset used for testing the model.\n",
        "        model: The trained TensorFlow model.\n",
        "\n",
        "    Returns:\n",
        "        A list of tuples containing the path to misclassified images, their true labels, and the predicted labels.\n",
        "    \"\"\"\n",
        "    labels = [\"00-scratched\", \"01-whole\"]\n",
        "    output_dir = 'misclassified_images'  # Directory to save misclassified images\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
        "\n",
        "    image_info = []  # Store info of misclassified images\n",
        "\n",
        "    # Iterate over all batches in the testing set\n",
        "    for batch_index, (images, truths) in enumerate(testing_set):\n",
        "        predictions = model.predict(images)  # Predict a whole batch for efficiency\n",
        "        for i, image in enumerate(images):\n",
        "            prediction = np.argmax(predictions[i])\n",
        "            truth = np.argmax(truths[i])\n",
        "            if prediction != truth:\n",
        "                # Save misclassified image\n",
        "                image_path = os.path.join(output_dir, f'image_{batch_index}_{i}.jpg')\n",
        "                tf.keras.utils.save_img(image_path, image.numpy())\n",
        "                # Append misclassification info\n",
        "                image_info.append((image_path, labels[truth], labels[prediction]))\n",
        "\n",
        "    return image_info"
      ],
      "metadata": {
        "id": "8gvop_cXYRoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_test_images(testing_set, model):\n",
        "    \"\"\"\n",
        "    Plot a 3x3 grid of images from the testing set with their true and predicted labels.\n",
        "\n",
        "    Args:\n",
        "        testing_set: The dataset used for testing the model.\n",
        "        model: The trained TensorFlow model.\n",
        "    \"\"\"\n",
        "    labels = [\"00-scratched\", \"01-whole\"]\n",
        "\n",
        "    it = iter(testing_set)\n",
        "    images, truths = next(it)  # Get a batch of test images and labels\n",
        "\n",
        "    predictions = model.predict(images)  # Predict the entire batch for efficiency\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "    fig.tight_layout()\n",
        "    fig.subplots_adjust(hspace=.25)\n",
        "\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            ax = axes[i, j]\n",
        "            image = images[i * 3 + j]\n",
        "            truth = np.argmax(truths[i * 3 + j])\n",
        "            prediction = np.argmax(predictions[i * 3 + j])\n",
        "            ax.set_title('Label: %s\\nPrediction: %s' % (labels[truth], labels[prediction]))\n",
        "            ax.imshow(image.numpy().astype(\"uint8\"))\n",
        "            ax.axis('off')  # Hide the axis\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "ISBtjaL1YXjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(testing_set, model, labels=[\"00-scratched\", \"01-whole\"]):\n",
        "    \"\"\"\n",
        "    Plot a confusion matrix for the model predictions on the testing set.\n",
        "\n",
        "    Args:\n",
        "        testing_set: The dataset used for testing the model.\n",
        "        model: The trained TensorFlow model.\n",
        "        labels: A list of label names corresponding to the classification labels.\n",
        "    \"\"\"\n",
        "    true_labels = []  # True labels\n",
        "    pred_labels = []  # Predicted labels\n",
        "\n",
        "    # Iterate through the testing set\n",
        "    for images, truths in testing_set:\n",
        "        predictions = model.predict(images)  # Predict the entire batch for efficiency\n",
        "        true_labels.extend(np.argmax(truths, axis=1))\n",
        "        pred_labels.extend(np.argmax(predictions, axis=1))\n",
        "\n",
        "    # Generate and plot the confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "5fpw9CXZYd9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture using VGG16 as a base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# Freeze the layers of the base model to not train them during the first training phase\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Building the model by adding custom layers on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')  # Assuming binary classification ('scratched' vs 'not scratched')\n",
        "])\n",
        "\n",
        "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define your callbacks (excluding Neptune's callback)\n",
        "callbacks = [checkpoint, earlystop]\n",
        "\n",
        "# Fit the model on the training data\n",
        "history = model.fit(training_set,\n",
        "                    epochs=15,\n",
        "                    validation_data=validation_set,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# After training, save the model and/or its weights locally\n",
        "model.save('best_model.h5')  # Save the entire model as a single HDF5 file.\n",
        "\n",
        "# Optionally, create a zip file of your model directory if you have saved checkpoints\n",
        "import shutil\n",
        "shutil.make_archive(\"best_checkpoint\", 'zip', \"best_checkpoint\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(testing_set)\n",
        "print(f'Test loss: {loss}, Test accuracy: {accuracy}')\n",
        "\n",
        "# Plotting the confusion matrix for the test set\n",
        "fig_cm = plot_confusion_matrix(testing_set, model)\n",
        "plt.show(fig_cm)\n",
        "\n",
        "# Plot test images with predictions\n",
        "fig_test_images = plot_test_images(testing_set, model)\n",
        "plt.show(fig_test_images)\n",
        "\n",
        "# Upload misclassified images (locally for now as Neptune is removed)\n",
        "misclass = upload_misclassified_images(testing_set, model)\n",
        "# You can print the misclassified images' paths or handle them as you wish here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3zTbLuVZY7ov",
        "outputId": "28068a5b-f6dc-44cc-d8ce-62e052b4a704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 17.3564 - accuracy: 0.7545\n",
            "Epoch 1: val_accuracy improved from -inf to 0.93846, saving model to ./best_checkpoint\n",
            "28/28 [==============================] - 425s 15s/step - loss: 17.3564 - accuracy: 0.7545 - val_loss: 6.8685 - val_accuracy: 0.9385\n",
            "Epoch 2/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 6.7492 - accuracy: 0.9122\n",
            "Epoch 2: val_accuracy did not improve from 0.93846\n",
            "28/28 [==============================] - 361s 13s/step - loss: 6.7492 - accuracy: 0.9122 - val_loss: 2.9086 - val_accuracy: 0.9308\n",
            "Epoch 3/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 6.6496 - accuracy: 0.9122 \n",
            "Epoch 3: val_accuracy did not improve from 0.93846\n",
            "28/28 [==============================] - 366s 13s/step - loss: 6.6496 - accuracy: 0.9122 - val_loss: 2.6257 - val_accuracy: 0.9385\n",
            "Epoch 4/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 4.8459 - accuracy: 0.9302\n",
            "Epoch 4: val_accuracy improved from 0.93846 to 0.94615, saving model to ./best_checkpoint\n",
            "28/28 [==============================] - 364s 13s/step - loss: 4.8459 - accuracy: 0.9302 - val_loss: 7.0676 - val_accuracy: 0.9462\n",
            "Epoch 5/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 4.2671 - accuracy: 0.9369\n",
            "Epoch 5: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 358s 13s/step - loss: 4.2671 - accuracy: 0.9369 - val_loss: 2.9697 - val_accuracy: 0.9385\n",
            "Epoch 6/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 4.8508 - accuracy: 0.9392 \n",
            "Epoch 6: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 362s 13s/step - loss: 4.8508 - accuracy: 0.9392 - val_loss: 5.8091 - val_accuracy: 0.9462\n",
            "Epoch 7/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 2.2343 - accuracy: 0.9505\n",
            "Epoch 7: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 358s 13s/step - loss: 2.2343 - accuracy: 0.9505 - val_loss: 5.4003 - val_accuracy: 0.9308\n",
            "Epoch 8/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 2.7526 - accuracy: 0.9685\n",
            "Epoch 8: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 357s 13s/step - loss: 2.7526 - accuracy: 0.9685 - val_loss: 4.5850 - val_accuracy: 0.9385\n",
            "Epoch 9/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.9963 - accuracy: 0.9595\n",
            "Epoch 9: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 417s 15s/step - loss: 1.9963 - accuracy: 0.9595 - val_loss: 4.2558 - val_accuracy: 0.9308\n",
            "Epoch 10/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.4586 - accuracy: 0.9775\n",
            "Epoch 10: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 359s 13s/step - loss: 1.4586 - accuracy: 0.9775 - val_loss: 4.9469 - val_accuracy: 0.9231\n",
            "Epoch 11/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.9842\n",
            "Epoch 11: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 357s 13s/step - loss: 0.7041 - accuracy: 0.9842 - val_loss: 5.1749 - val_accuracy: 0.9385\n",
            "Epoch 12/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 2.6797 - accuracy: 0.9595\n",
            "Epoch 12: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 356s 13s/step - loss: 2.6797 - accuracy: 0.9595 - val_loss: 8.9940 - val_accuracy: 0.9385\n",
            "Epoch 13/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.8555 - accuracy: 0.9775\n",
            "Epoch 13: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 357s 13s/step - loss: 0.8555 - accuracy: 0.9775 - val_loss: 5.7329 - val_accuracy: 0.9462\n",
            "Epoch 14/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.7398 - accuracy: 0.9730\n",
            "Epoch 14: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 357s 13s/step - loss: 1.7398 - accuracy: 0.9730 - val_loss: 5.7096 - val_accuracy: 0.9462\n",
            "Epoch 15/15\n",
            "28/28 [==============================] - ETA: 0s - loss: 1.8124 - accuracy: 0.9662\n",
            "Epoch 15: val_accuracy did not improve from 0.94615\n",
            "28/28 [==============================] - 358s 13s/step - loss: 1.8124 - accuracy: 0.9662 - val_loss: 5.3412 - val_accuracy: 0.9385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 39s 9s/step - loss: 4.2186 - accuracy: 0.9677\n",
            "Test loss: 4.21858024597168, Test accuracy: 0.9677419066429138\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'confusion_matrix' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7828e3f97845>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Plotting the confusion matrix for the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mfig_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-12908eacf9bd>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(testing_set, model, labels)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Generate and plot the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
          ]
        }
      ]
    }
  ]
}